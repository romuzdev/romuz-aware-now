/**
 * M17: Knowledge Hub + RAG - Edge Function
 * Function: knowledge-rag
 * Purpose: Generate AI answers using Retrieval-Augmented Generation
 * 
 * This function receives a question and relevant context chunks,
 * then uses Lovable AI to generate an accurate, contextual answer.
 */

import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

interface RAGRequest {
  question: string;
  context: string;
  language?: 'ar' | 'en';
  sources?: Array<{ article_id: string; title: string }>;
}

serve(async (req) => {
  // Handle CORS preflight
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    console.log('ðŸ¤– knowledge-rag: Starting RAG query processing');
    
    const {
      question,
      context,
      language = 'ar',
      sources = [],
    }: RAGRequest = await req.json();

    if (!question || question.trim().length === 0) {
      throw new Error('Question is required and cannot be empty');
    }

    if (!context || context.trim().length === 0) {
      throw new Error('Context is required and cannot be empty');
    }

    // Get Lovable AI API Key
    const LOVABLE_API_KEY = Deno.env.get('LOVABLE_API_KEY');
    if (!LOVABLE_API_KEY) {
      throw new Error('LOVABLE_API_KEY is not configured');
    }

    console.log(`ðŸ“ Processing question: "${question.substring(0, 50)}..." (Language: ${language})`);

    // Prepare system prompt based on language
    const systemPrompt = language === 'ar'
      ? `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªØ§Ø­Ø©.

Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
1. Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ÙÙ‚Ø¯Ù…
2. Ø£Ø¬Ø¨ Ø¨Ø´ÙƒÙ„ Ø¯Ù‚ÙŠÙ‚ ÙˆÙ…Ø¨Ø§Ø´Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„
3. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ØŒ Ù‚Ù„ Ø°Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­
4. Ø§Ø°ÙƒØ± Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„ØªÙŠ Ø§Ø³ØªØ®Ø¯Ù…ØªÙ‡Ø§ ÙÙŠ Ø¥Ø¬Ø§Ø¨ØªÙƒ
5. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰
6. Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙÙ‡ÙˆÙ…Ø©`
      : `You are an intelligent assistant specialized in answering questions based on the available knowledge base.

Answer guidelines:
1. Use only the information provided in the context
2. Answer accurately and directly to the question
3. If you don't find the answer in the context, state that clearly
4. Mention the sources you used in your answer
5. Use clear and professional English
6. Make the answer clear and understandable`;

    const userPrompt = language === 'ar'
      ? `Ø§Ù„Ø³Ø¤Ø§Ù„: ${question}

Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ØªØ§Ø­:
${context}

Ø§Ù„Ù…ØµØ§Ø¯Ø±:
${sources.map((s, i) => `${i + 1}. ${s.title}`).join('\n')}

Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ø´Ø§Ù…Ù„Ø© ÙˆØ¯Ù‚ÙŠÙ‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…ÙÙ‚Ø¯Ù….`
      : `Question: ${question}

Available Context:
${context}

Sources:
${sources.map((s, i) => `${i + 1}. ${s.title}`).join('\n')}

Please provide a comprehensive and accurate answer based on the provided context.`;

    // Call Lovable AI for RAG response
    const aiResponse = await fetch('https://ai.gateway.lovable.dev/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${LOVABLE_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'google/gemini-2.5-flash',
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt },
        ],
        temperature: 0.3, // Lower temperature for more focused, factual answers
        max_tokens: 1000,
      }),
    });

    if (!aiResponse.ok) {
      const errorText = await aiResponse.text();
      console.error('âŒ Lovable AI error:', aiResponse.status, errorText);
      
      if (aiResponse.status === 429) {
        return new Response(
          JSON.stringify({ error: 'Rate limit exceeded. Please try again later.' }),
          { status: 429, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        );
      }
      
      if (aiResponse.status === 402) {
        return new Response(
          JSON.stringify({ error: 'Payment required. Please add credits to your Lovable AI workspace.' }),
          { status: 402, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
        );
      }
      
      throw new Error(`Lovable AI API error: ${aiResponse.status}`);
    }

    const aiData = await aiResponse.json();
    const answer = aiData.choices[0]?.message?.content;

    if (!answer) {
      throw new Error('Failed to generate answer from AI');
    }

    console.log(`âœ… Successfully generated RAG answer (${answer.length} characters)`);

    // Calculate confidence score based on context similarity and answer quality
    const confidence = calculateConfidence(question, context, answer);

    return new Response(
      JSON.stringify({
        success: true,
        answer,
        confidence,
        model: 'google/gemini-2.5-flash',
        sources: sources.map(s => s.article_id),
        language,
      }),
      {
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );

  } catch (error) {
    console.error('âŒ Error in knowledge-rag:', error);
    
    return new Response(
      JSON.stringify({
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error occurred',
      }),
      {
        status: 500,
        headers: { ...corsHeaders, 'Content-Type': 'application/json' },
      }
    );
  }
});

/**
 * Calculate confidence score for the RAG answer
 */
function calculateConfidence(question: string, context: string, answer: string): number {
  // Simple heuristic-based confidence calculation
  let confidence = 0.5; // Base confidence

  // Higher confidence if answer is longer and more detailed
  if (answer.length > 200) confidence += 0.1;
  if (answer.length > 500) confidence += 0.1;

  // Higher confidence if context is substantial
  if (context.length > 500) confidence += 0.1;
  if (context.length > 1000) confidence += 0.1;

  // Lower confidence if answer contains uncertainty phrases
  const uncertaintyPhrases = [
    'Ù„Ø§ Ø£Ø¹Ù„Ù…',
    'ØºÙŠØ± Ù…ØªØ£ÙƒØ¯',
    'Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹',
    'Ù„Ø§ Ø£Ø¬Ø¯',
    "I don't know",
    'not sure',
    'cannot find',
  ];

  const hasUncertainty = uncertaintyPhrases.some(phrase =>
    answer.toLowerCase().includes(phrase.toLowerCase())
  );

  if (hasUncertainty) confidence -= 0.2;

  // Ensure confidence is between 0 and 1
  return Math.max(0, Math.min(1, confidence));
}
